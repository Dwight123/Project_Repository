{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Name: Dwight Devens\n",
    "#### Student ID: A15711217"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 190 Final Project\n",
    "\n",
    "### Suggested Project 1\n",
    "\n",
    "### Composing Melody Using RNN with Attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/dwight/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.io import wavfile\n",
    "from numpy.linalg import svd\n",
    "from scipy.stats.mstats import gmean\n",
    "from matplotlib import rcParams\n",
    "import scipy\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Lambda\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "filePathToWeights = 'weights.hdf5'\n",
    "lengthOfSequenceProduced = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructMelodies(notes, pitches, n_vocab):\n",
    "    # Map notes to integers\n",
    "    noteToIntegerDict = dict((note, number) for number, note in enumerate(pitches))\n",
    "\n",
    "    numberOfNotesForPrediction = 8\n",
    "    networkInput = []\n",
    "    networkOutput = []\n",
    "    for i in range(0, len(notes) - numberOfNotesForPrediction, 1):\n",
    "        # Input\n",
    "        inputSequence = notes[i:i + numberOfNotesForPrediction]\n",
    "        networkInput.append([noteToIntegerDict[char] for char in inputSequence])\n",
    "        # Output\n",
    "        outputSequence = notes[i + numberOfNotesForPrediction]\n",
    "        networkOutput.append(noteToIntegerDict[outputSequence])\n",
    "    # Store the length\n",
    "    theNetworkPatttern = len(networkInput)\n",
    "\n",
    "    # Had to change shape for LSTM layers or it wasn't working\n",
    "    inputAfterNormalization = np.reshape(networkInput, (theNetworkPatttern, numberOfNotesForPrediction, 1))\n",
    "    inputAfterNormalization = inputAfterNormalization / float(n_vocab)\n",
    "\n",
    "    return (networkInput, inputAfterNormalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the next note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_note(model, networkInput, pitches, n_vocab):\n",
    "    # Changed to a random start point to try to get better output\n",
    "    randomStartingPoint = np.random.randint(0, len(networkInput)-1)\n",
    "    # Map the integers back to the notes\n",
    "    integerToNoteDict = dict((number, note) for number, note in enumerate(pitches))\n",
    "\n",
    "    thePattern = networkInput[randomStartingPoint]\n",
    "    # Prediction to return\n",
    "    actualPrediction = []\n",
    "\n",
    "    # Note generation\n",
    "    for note_index in range(lengthOfSequenceProduced):\n",
    "        # Reshape and normalize\n",
    "        predictionInput = np.reshape(thePattern, (1, len(thePattern), 1))\n",
    "        predictionInput = predictionInput / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(predictionInput, verbose=0)\n",
    "        #print(\"prediction = \", prediction)\n",
    "\n",
    "        index = np.argmax(prediction)\n",
    "        \n",
    "        # Wrote to catch error, so far error is gone, delete later if needed\n",
    "        if index in integerToNoteDict:\n",
    "            result = integerToNoteDict[index]\n",
    "        else:\n",
    "            result = 'error'\n",
    "        # Add the prediction\n",
    "        actualPrediction.append(result)\n",
    "        # Then add to the pattern\n",
    "        thePattern.append(index)\n",
    "        thePattern = thePattern[1:len(thePattern)]\n",
    "\n",
    "    return actualPrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructNetwork(networkInput, n_vocab):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, input_shape=(networkInput.shape[1], networkInput.shape[2]),\n",
    "                   recurrent_dropout=0.3, return_sequences=True))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    \n",
    "    # 2. A batch normalization layer. \n",
    "    # Keras documentation - \"Layer that normalizes its inputs. Batch normalization \n",
    "    # applies a transformation that maintains the mean output close to 0 and the output \n",
    "    # standard deviation close to 1.\"\"\n",
    "    # Example: Args look optional, just instantiate for now\n",
    "    model.add(BatchNorm())\n",
    "    \n",
    "    # 3. A layer which drops 3/10 of the units. \n",
    "    # Keras documentation - \"The Dropout layer randomly sets input units to 0 with a \n",
    "    # frequency of rate at each step during training time, \n",
    "    # which helps prevent overfitting. \n",
    "    # Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all \n",
    "    # inputs is unchanged.\"\"\n",
    "    # Example: tf.keras.layers.Dropout(rate, noise_shape=None, seed=None, **kwargs)\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # 4. A fully connected layer with 256 units of output. \n",
    "    # Keras documentation - \"Just your regular densely-connected NN layer.\"\n",
    "    # Example: model.add(tf.keras.layers.Dense(32))\n",
    "    model.add(Dense(256))\n",
    "    \n",
    "    # 5. A ReLU activation layer. \n",
    "    # Keras documentatino - \"Applies an activation function to an output.\n",
    "    # Arguments - activation: Activation function, such as tf.nn.relu, \n",
    "    # or string name of built-in activation function, such as \"relu\".\"\n",
    "    # Example: layer = tf.keras.layers.Activation('relu')\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # 6. A batch normalization layer. \n",
    "    # Keras documentation - \"Layer that normalizes its inputs. Batch normalization \n",
    "    # applies a transformation that maintains the mean output close to 0 and the output \n",
    "    # standard deviation close to 1.\"\"\n",
    "    # Example: Args look optional, just instantiate for now\n",
    "    model.add(BatchNorm())\n",
    "    \n",
    "    # 7. A layer which drops 3/10 of the units. \n",
    "    # Keras documentation - \"The Dropout layer randomly sets input units to 0 with a \n",
    "    # frequency of rate at each step during training time, \n",
    "    # which helps prevent overfitting. \n",
    "    # Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all \n",
    "    # inputs is unchanged.\"\"\n",
    "    # Example: tf.keras.layers.Dropout(rate, noise_shape=None, seed=None, **kwargs)\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # 8. A fully connected layer with number of units of output equal to the vocabulary \n",
    "    # space of the input. \n",
    "    # Keras documentation - \"Just your regular densely-connected NN layer.\"\n",
    "    # Example: model.add(tf.keras.layers.Dense(32))\n",
    "    # but this time need vocab space of input, which = n_vocab  \n",
    "    model.add(Dense(n_vocab))\n",
    "    \n",
    "    # 9. A softmax activation layer which uses a temperature of .6 \n",
    "    # (Note, you may need to define this as two separate layers in Keras, \n",
    "    # using the definition of temperature for softmax)\n",
    "    \n",
    "    # Keras documentation - \"Softmax converts a vector of values to a probability \n",
    "    # distribution. The elements of the output vector are in range (0, 1) and sum to 1.\n",
    "    # Each vector is handled independently. The axis argument sets which axis of the \n",
    "    # input the function is applied along. Softmax is often used as the activation \n",
    "    # for the last layer of a classification network because the result could be \n",
    "    # interpreted as a probability distribution. The softmax of each vector x is \n",
    "    # computed as exp(x) / tf.reduce_sum(exp(x)). The input values in are the log-odds \n",
    "    # of the resulting probability.\n",
    "    # Arguments - x : Input tensor. axis: Integer, axis along which the softmax \n",
    "    # normalization is applied.\"\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # After creating your network, compile the model with categorical cross entropy loss \n",
    "    # and an optimizer of your choice. \n",
    "    # Example: model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    # Load the weights to each node\n",
    "    model.load_weights(filePathToWeights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildMidiOutputFile(actualPrediction):\n",
    "    bufferBetween = 0\n",
    "    # Leave this at 0.5 for now\n",
    "    bufferAmount = 0.5\n",
    "    notesForTheOutput = []\n",
    "    \n",
    "    # For each pattern\n",
    "    for thePattern in actualPrediction:\n",
    "        # If the pattern is a note\n",
    "        if ('.' in thePattern) or thePattern.isdigit():    \n",
    "            # Create new note and append to output\n",
    "            newNote = note.Note(thePattern)\n",
    "            newNote.storedInstrument = instrument.Piano()\n",
    "            newNote.bufferBetween = bufferBetween\n",
    "            notesForTheOutput.append(newNote)  \n",
    "        # Else it is a chord\n",
    "        else:\n",
    "            chordNotes = thePattern.split('.')\n",
    "            notes = []\n",
    "            # Then for each note in the chord\n",
    "            for thisNote in chordNotes:\n",
    "                # Add the notes together\n",
    "                newNote = note.Note(int(thisNote))\n",
    "                newNote.storedInstrument = instrument.Piano()\n",
    "                notes.append(newNote)\n",
    "            # And create a new chord and append the output\n",
    "            newChord = chord.Chord(notes)\n",
    "            newChord.bufferBetween = bufferBetween\n",
    "            notesForTheOutput.append(newChord)\n",
    "\n",
    "        # Add a buffer between the notes each time\n",
    "        bufferBetween += bufferAmount\n",
    "        \n",
    "    # Construct the midi output file\n",
    "    midiOutput = stream.Stream(notesForTheOutput)\n",
    "    midiOutput.write('midi', fp='outputFile.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the whole project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runProject():\n",
    "    # Load the training data you created\n",
    "    with open('MyData/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "    # Sort the pitches and store amount\n",
    "    sortedPitches = sorted(set(item for item in notes))\n",
    "    n_vocab = len(set(notes))\n",
    "    # Build the melodies\n",
    "    networkInput, inputAfterNormalization = constructMelodies(notes, sortedPitches, n_vocab)\n",
    "    # Build the model\n",
    "    model = constructNetwork(inputAfterNormalization, n_vocab)\n",
    "    # Make the prediction\n",
    "    actualPrediction = generate_next_note(model, networkInput, sortedPitches, n_vocab)\n",
    "    # Create the file from the prediction\n",
    "    buildMidiOutputFile(actualPrediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "generate()\n",
      "n_vocab =  186\n",
      "WARNING:tensorflow:From /Users/dwight/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "#print(\"start\")\n",
    "runProject()\n",
    "#print(\"finish\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
